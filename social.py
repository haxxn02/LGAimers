import os
import json
import time
from openai import OpenAI
from tqdm import tqdm
from dotenv import load_dotenv # [ì¶”ê°€ëœ ë¶€ë¶„]

# 1. .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# 2. í™˜ê²½ë³€ìˆ˜ì—ì„œ í† í° ê°€ì ¸ì˜¤ê¸°
FRIENDLI_TOKEN = os.getenv("FRIENDLI_TOKEN")

# [ì•ˆì „ì¥ì¹˜] í† í°ì´ ì˜ ë¶ˆëŸ¬ì™€ì¡ŒëŠ”ì§€ í™•ì¸
if not FRIENDLI_TOKEN:
    print("âŒ ì˜¤ë¥˜: .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
    print("test.pyì™€ ê°™ì€ í´ë”ì— .env íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

client = OpenAI(
    api_key=FRIENDLI_TOKEN,
    base_url="https://api.friendli.ai/serverless/v1"
)

# ëª¨ë¸ ID
TEACHER_MODEL_ID = "LGAI-EXAONE/K-EXAONE-236B-A23B"

# ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ (ìµœì†Œ 500ê°œ ëª©í‘œ!)
seed_prompts = [
    "ëŒ€í•œë¯¼êµ­ì˜ AI ì‚°ì—… ë°œì „ ë°©í–¥ì— ëŒ€í•´ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.",
    "Explain the key differences between quantization and pruning in LLMs.",
    "ì‚¬ê³¼, ë°”ë‚˜ë‚˜, ë”¸ê¸°ì˜ ê³µí†µì ê³¼ ì°¨ì´ì ì„ ë¹„êµ ë¶„ì„í•´ì¤˜.",
    "íŒŒì´ì¬ì„ ì‚¬ìš©í•˜ì—¬ í€µ ì •ë ¬(Quick Sort) ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•´ì¤˜.",
    "Write a C++ code to implement a binary search tree insertion.",
    "Pytorchë¡œ ê°„ë‹¨í•œ CNN ëª¨ë¸ì„ ì •ì˜í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´.",
    "ë¯¸ë¶„ê³¼ ì ë¶„ì˜ ê´€ê³„ë¥¼ ê³ ë“±í•™ìƒì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì¤˜.",
    "What is the theory of relativity?",
    "ì…°ìµìŠ¤í”¼ì–´ì˜ í–„ë¦¿ ì¤„ê±°ë¦¬ë¥¼ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.",
    "AI ìœ¤ë¦¬ì— ëŒ€í•œ ì§§ì€ ì—ì„¸ì´ë¥¼ ì‘ì„±í•´ì¤˜."
]

output_file = "exaone_social_dataset.jsonl"
print(f"ğŸš€ ë°ì´í„° ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ëª¨ë¸: {TEACHER_MODEL_ID})")

successful_count = 0
with open(output_file, "a", encoding="utf-8") as f:
    for prompt in tqdm(seed_prompts):
        
        for attempt in range(5): 
            try:
                response = client.chat.completions.create(
                    model=TEACHER_MODEL_ID,
                    messages=[
                        {"role": "system", "content": "You are EXAONE, a helpful AI assistant."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1024,
                    # temperature=0.7 (ì‚­ì œë¨)
                )
                
                answer = response.choices[0].message.content
                
                data_point = {
                    "instruction": prompt,
                    "output": answer
                }
                f.write(json.dumps(data_point, ensure_ascii=False) + "\n")
                f.flush()
                successful_count += 1
                
                time.sleep(2) 
                break 
                
            except Exception as e:
                error_msg = str(e)
                if "429" in error_msg or "Rate limit" in error_msg:
                    print(f"\nâ³ ë„ˆë¬´ ë¹¨ë¼ìš”! 10ì´ˆ ëŒ€ê¸° ì¤‘... (ì‹œë„ {attempt+1}/5)")
                    time.sleep(10)
                elif "422" in error_msg:
                    print(f"\nâŒ ì„¤ì • ì˜¤ë¥˜: {e}")
                    break
                else:
                    print(f"\nâŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
                    time.sleep(5)

print(f"\nâœ… ì™„ë£Œ! ì´ {successful_count}ê°œì˜ ë°ì´í„°ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")